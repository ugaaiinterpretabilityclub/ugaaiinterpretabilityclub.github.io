<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Understanding Our Topic</title>
    <link rel="stylesheet" href="/style.css">
</head>
<body>

<!-- Reusable navbar -->
<div id="navbar"></div>

<main>
    <article class="blog-post">
        <header>
            <h2>FMI At UGA: Why?</h2>
            <p class="author">By James Squires · January 2026</p>
        </header>

        <section>

            <p>
                I chose to invite those around me to start this DRG with me in order to permit an academic ecosystem that is virtually non-existant at UGA: AI interpretability and formal methods. Although UGA's AI department is quite large,
                there is little to no research emphasis on one of the most pertinent problems of our decade: how do we understand the internal structures of AI? This problem is important enough to me that I want to do research in it, but if
                there's no ecosystem to do so, the next best thing is to collaboratively learn it with other like-minded, motivated people.
            </p>

            <p>
                Similarly, logic is a prevailing subject that has deep and intertwined relations with AI, particularly it's mathematical formalizations and applications. Type theory, in particular, enables a field of automated theorem proving
                that would otherwise not be possible. If we can gurantee the theorems AI generates are mathematically correct via type-checking, then the question becomes how to efficiently search our proof-state space. It turns a problem that feels
                more like trying to produce Shakespeare from monkey's with typewriters into a legitimate computer science question about how to effectively comb the possible proofs for a given theorem statement.
            </p>
            <p>
                Category theory, on the otherhand, has intimate ties to both AI interpretability and type theory. Categories allow us to view AI compositionally; what happens when we combine or interchange layers? But it also allows us to further boost
                and explain our type theory. The most nascent yet promising field that attempts to do this is Homotopy Type Theory, in which one uses Martin-Löf type theory to soup out their categorical language, although I know little to nothing about the field
                (which is why I'd be interested in hosting a DRG for it with this group in a future semester).
            </p>
            <p>
                With all this being said, it seems like logic and AI interpretability, both of which have undersupported ecosystems at UGA, are rewarding to study concomitantly. I don't claim to be an expert on any of these topics, but I'm happy to learn alongside
                fellow enthusiasts so that someday I might be an expert. That's why the formatting of this group intends to create a research-adjacent group study, in which we utilize all our members backgrounds to arrive at a cogent understanding of these topics.
            </p>
        </section>

        <!-- About the Author Section -->
        <section class="about-author">
            <h3>About James Squires</h3>
            <p>
                I'm a third year math and physics major who does a wide array of research in machine learning, optimization, categorical quantum computing, and recently, categorical AI. I particularly love type theory and category theory.
            </p>
            <a href="mailto:ugaaiinterpretabilityclub@gmail.com" class="contact-button">Email Me</a>
        </section>
    </article>
</main>

<!-- Reusable footer -->
<div id="footer"></div>

<script src="/main.js"></script>
</body>
</html>
